{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pyspark.sql.functions import col, size, split, input_file_name \n",
    "from pyspark.sql.types import StructType, StructField, StringType, DecimalType, DateType, TimestampType, IntergerType \n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoloader(\n",
    "        datasource, \n",
    "        format, \n",
    "        checkpoint,\n",
    "        table_name, \n",
    "        schema, \n",
    "        file\n",
    "):\n",
    "    logger.info(\"start reading data using readstream\")\n",
    "\n",
    "    query = (\n",
    "        spark.readstream\n",
    "        .format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\", format)\n",
    "        .option(\"cloudFiles.schemaLocation\", checkpoint) # this is where autoloader will house metadata \n",
    "        .option(\"cloudFiles.includeExistingFiles\", \"true\") # Includes existing files in the file path \n",
    "        .option(\"cloudFiles.useIncrementalListing\", \"true\") # use incremental listing to detect new files \n",
    "        .option(\"recursiveFileLookup\", \"true\") # enable recursive file lookup \n",
    "        .option(\"header\", \"true\")\n",
    "        .opiton(\"pathGlobFilter\", f\"*{file}*\") # this is a file patter that will be use to filter file name\n",
    "        .schema(schema)\n",
    "        .load(datasource)\n",
    "    )\n",
    "\n",
    "    # Running transofmation on streamed data\n",
    "\n",
    "    query = query.withColumn(\"input_file_name\", input_file_name())\n",
    "\n",
    "    query = query.withColumn(\"split\", split(query[\"input_file_name\"]), \"/\")\n",
    "\n",
    "    query = query.withColumn(\"input_file_name\", query[\"split\"][6])\n",
    "\n",
    "    query = query.drop(query[\"split\"])\n",
    "\n",
    "    load = (\n",
    "        query.writeStream\n",
    "        .format(\"delta\")\n",
    "        .option(\"checkpointLocation\", checkpoint)\n",
    "        .option(\"mergeSchema\", \"true\")\n",
    "        .tirgger(avialable=True)\n",
    "        .toTable(table_name)\n",
    "    )\n",
    "\n",
    "    return load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dict = {\n",
    "    \"user_name\": StructType(\n",
    "    [\n",
    "        StructField(\"FIRST_NAME\", StringType(), True),\n",
    "        StructField(\"LAST_NAME\", StringType(), True), \n",
    "        StructField(\"USERID\", StringType(), True), \n",
    "        StructField(\"USER_EMAIL\", StringType(), True), \n",
    "        StructField(\"PHONE_NUMBER\", IntergerType(), True)\n",
    "    ]\n",
    "),\n",
    "\"user_address\": StructType(\n",
    "    [\n",
    "        StructField(\"ADDRESS\", StringType(), True),\n",
    "        StructField(\"CITY\", StringType(), True), \n",
    "        StructField(\"STATE\", StringType(), True), \n",
    "        StructField(\"ZIPCODE\", StringType(), True), \n",
    "        StructField(\"USERID\", IntergerType(), True)\n",
    "    ]\n",
    ")\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = \"/volumes/em_catalog/em_schema/files\"\n",
    "\n",
    "for v, k in files_dict.items():\n",
    "    checkpoint = f\"/volumes/em_catalog/em_schema/checkpoint/{v}\"\n",
    "    table = v.upper() \n",
    "    schema = k \n",
    "    catalog = \"em_catalog\"\n",
    "    schema_name = \"em_schema\" \n",
    "    table_name = f\"{catalog}.{schema_name}.{table}_inbound\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
