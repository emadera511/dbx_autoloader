{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catlog = em_test\n",
    "schema = emad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(f\"\"\"\n",
    "\n",
    "with provider as ( \n",
    "    select distinct provider_id, provider_detail, provider_npi\n",
    "    from {catlog}.{schema}.provider\n",
    "    wehre provider_id is not null\n",
    "), \n",
    "\n",
    "practice as ( \n",
    "    select distinct practice_id, practice_name, practice_npi, practice_location, practice_lat, practice_long\n",
    "    from {catlog}.{schema}.practice a\n",
    "    inner join location l on a.practice_npi = l.npi \n",
    "), \n",
    "\n",
    "member as ( \n",
    "    select distinct member_id, member_name, member_dob\n",
    "    from {catlog}.{schema}.member\n",
    ")\n",
    "\n",
    "select * \n",
    "from {catlog}.{schema}.claims c \n",
    "inner join provider p on c.provider_id = p.provider_id \n",
    "inner join practice pr on c.practice_id = pr.practice_id \n",
    "inner join member m on c.member_id = m.member_id \n",
    "        \n",
    "\"\"\")\n",
    "\n",
    "df.write.format(\"delta\").option(\"inferSchema\",\"true\").saveAsTable(f\"{catlog}.{schema}.claim_analysis\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
